{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Short answer — in super simple terms:\n",
      "- The Model Context Protocol (MCP) is a simple, open standard that lets an LLM (the “brain”) talk to external tools and data (the “helpers”) in a regular, predictable way — like a USB-C port for AI. It lets models list available tools (what helpers can do) and call them to get facts or take actions. ([en.wikipedia.org](https://en.wikipedia.org/wiki/Model_Context_Protocol?utm_source=openai))\n",
      "\n",
      "How it works (very simply)\n",
      "1. Someone runs an MCP server that exposes tools (examples: “list files”, “search email”, “call calendar”).  \n",
      "2. The model (or an agent framework) asks the server “what tools do you have?” and then can ask “run tool X with these inputs.”  \n",
      "3. The server executes the tool and streams back results; the model uses that to form its reply. Transports include hosted endpoints, HTTP (with streaming/SSE), or plain stdio for local processes. ([openai.github.io](https://openai.github.io/openai-agents-js/guides/mcp/?utm_source=openai))\n",
      "\n",
      "Why you’d use it (super short)\n",
      "- You don’t need a custom adapter for each data source — MCP standardizes the connection so many models and apps can reuse the same tools. ([theverge.com](https://www.theverge.com/2024/11/25/24305774/anthropic-model-context-protocol-data-sources?utm_source=openai))\n",
      "\n",
      "A very small recipe to build a simple MCP-powered agent (zero-to-demo)\n",
      "1. Pick an MCP server to expose some simple tool (for a demo you can use a ready filesystem MCP server). ([openai.github.io](https://openai.github.io/openai-agents-js/guides/mcp/?utm_source=openai))  \n",
      "2. In your app, use an Agent SDK that understands MCP (OpenAI’s Agents SDK examples show how). Connect the MCP server to the agent as a tool source. ([openai.github.io](https://openai.github.io/openai-agents-js/guides/mcp/?utm_source=openai))  \n",
      "3. Ask the agent a question — the agent will discover tools via list_tools() and call the appropriate tool automatically. ([openai.github.io](https://openai.github.io/openai-agents-js/guides/mcp?utm_source=openai))\n",
      "\n",
      "Minimal Node.js example (conceptual; based on the OpenAI Agents SDK)\n",
      "- Install the SDK (example packages shown in the docs), and run a filesystem MCP server (or any example server).\n",
      "- Then create & run the agent that points to the stdio MCP server:\n",
      "\n",
      "const { Agent, run, MCPServerStdio } = require('@openai/agents');\n",
      "const path = require('path');\n",
      "\n",
      "async function main() {\n",
      "  const samplesDir = path.join(__dirname, 'sample_files');\n",
      "  const mcpServer = new MCPServerStdio({\n",
      "    name: 'Local FS MCP',\n",
      "    fullCommand: `npx -y @modelcontextprotocol/server-filesystem ${samplesDir}`,\n",
      "  });\n",
      "  await mcpServer.connect();\n",
      "\n",
      "  const agent = new Agent({\n",
      "    name: 'FS Assistant',\n",
      "    instructions: 'Use the MCP tools to answer file questions.',\n",
      "    mcpServers: [mcpServer],\n",
      "  });\n",
      "\n",
      "  const result = await run(agent, 'List the files in my sample directory.');\n",
      "  console.log('Agent reply:', result.finalOutput);\n",
      "\n",
      "  await mcpServer.close();\n",
      "}\n",
      "main().catch(console.error);\n",
      "\n",
      "(This is the same pattern shown in the OpenAI Agents docs — you can swap the server and transport type as needed.) ([openai.github.io](https://openai.github.io/openai-agents-js/guides/mcp/?utm_source=openai))\n",
      "\n",
      "Important safety notes (super important, short)\n",
      "- Only run MCP servers you trust. A malicious MCP server can exfiltrate data or misuse permissions. Audit packages and restrict which tools are exposed. ([itpro.com](https://www.itpro.com/security/a-malicious-mcp-server-is-silently-stealing-user-emails?utm_source=openai))  \n",
      "- Use tool-filtering and require human approval for dangerous actions when possible. ([openai.github.io](https://openai.github.io/openai-agents-js/guides/mcp?utm_source=openai))\n",
      "\n",
      "If you want, I can:\n",
      "- Give you a runnable step-by-step (exact install commands + a tiny sample-files directory) for Node.js or Python, or  \n",
      "- Show a simpler conceptual diagram if you prefer visuals.\n",
      "\n",
      "Which would you like next: a runnable Node/Python tutorial, or a simpler conceptual diagram?\n"
     ]
    }
   ],
   "source": [
    "from agents import Agent, Runner, WebSearchTool\n",
    "\n",
    "agent = Agent(\n",
    "    name=\"Assistant\",\n",
    "    model=\"gpt-5-mini\",\n",
    "    tools=[\n",
    "        WebSearchTool(),\n",
    "    ],\n",
    ")\n",
    "\n",
    "\n",
    "result = await Runner.run(agent, \"What is the model context protocol and how to build a simple agent with it in super simpler terms?\")\n",
    "print(result.final_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fetch_weather\n",
      "Fetch the weather for a given location.\n",
      "{\n",
      "  \"$defs\": {\n",
      "    \"Location\": {\n",
      "      \"properties\": {\n",
      "        \"lat\": {\n",
      "          \"title\": \"Lat\",\n",
      "          \"type\": \"number\"\n",
      "        },\n",
      "        \"long\": {\n",
      "          \"title\": \"Long\",\n",
      "          \"type\": \"number\"\n",
      "        }\n",
      "      },\n",
      "      \"required\": [\n",
      "        \"lat\",\n",
      "        \"long\"\n",
      "      ],\n",
      "      \"title\": \"Location\",\n",
      "      \"type\": \"object\",\n",
      "      \"additionalProperties\": false\n",
      "    }\n",
      "  },\n",
      "  \"properties\": {\n",
      "    \"location\": {\n",
      "      \"description\": \"The location to fetch the weather for.\",\n",
      "      \"properties\": {\n",
      "        \"lat\": {\n",
      "          \"title\": \"Lat\",\n",
      "          \"type\": \"number\"\n",
      "        },\n",
      "        \"long\": {\n",
      "          \"title\": \"Long\",\n",
      "          \"type\": \"number\"\n",
      "        }\n",
      "      },\n",
      "      \"required\": [\n",
      "        \"lat\",\n",
      "        \"long\"\n",
      "      ],\n",
      "      \"title\": \"Location\",\n",
      "      \"type\": \"object\",\n",
      "      \"additionalProperties\": false\n",
      "    }\n",
      "  },\n",
      "  \"required\": [\n",
      "    \"location\"\n",
      "  ],\n",
      "  \"title\": \"fetch_weather_args\",\n",
      "  \"type\": \"object\",\n",
      "  \"additionalProperties\": false\n",
      "}\n",
      "\n",
      "fetch_data\n",
      "Read the contents of a file.\n",
      "{\n",
      "  \"properties\": {\n",
      "    \"path\": {\n",
      "      \"description\": \"The path to the file to read.\",\n",
      "      \"title\": \"Path\",\n",
      "      \"type\": \"string\"\n",
      "    },\n",
      "    \"directory\": {\n",
      "      \"anyOf\": [\n",
      "        {\n",
      "          \"type\": \"string\"\n",
      "        },\n",
      "        {\n",
      "          \"type\": \"null\"\n",
      "        }\n",
      "      ],\n",
      "      \"description\": \"The directory to read the file from.\",\n",
      "      \"title\": \"Directory\"\n",
      "    }\n",
      "  },\n",
      "  \"required\": [\n",
      "    \"path\",\n",
      "    \"directory\"\n",
      "  ],\n",
      "  \"title\": \"fetch_data_args\",\n",
      "  \"type\": \"object\",\n",
      "  \"additionalProperties\": false\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "from typing_extensions import TypedDict, Any\n",
    "\n",
    "from agents import Agent, FunctionTool, RunContextWrapper, function_tool\n",
    "\n",
    "\n",
    "class Location(TypedDict):\n",
    "    lat: float\n",
    "    long: float\n",
    "\n",
    "@function_tool  \n",
    "async def fetch_weather(location: Location) -> str:\n",
    "    \n",
    "    \"\"\"Fetch the weather for a given location.\n",
    "\n",
    "    Args:\n",
    "        location: The location to fetch the weather for.\n",
    "    \"\"\"\n",
    "    # In real life, we'd fetch the weather from a weather API\n",
    "    return f\"The weather in this location: {location.lat}, {location.long} is sunny\"\n",
    "\n",
    "\n",
    "@function_tool(name_override=\"fetch_data\")  \n",
    "def read_file(ctx: RunContextWrapper[Any], path: str, directory: str | None = None) -> str:\n",
    "    \"\"\"Read the contents of a file.\n",
    "\n",
    "    Args:\n",
    "        path: The path to the file to read.\n",
    "        directory: The directory to read the file from.\n",
    "    \"\"\"\n",
    "    # In real life, we'd read the file from the file system\n",
    "    return \"<file contents>\"\n",
    "\n",
    "\n",
    "# agent = Agent(\n",
    "#     name=\"Assistant\",\n",
    "#     model=\"gpt-5-mini\",\n",
    "#     tools=[fetch_weather, read_file],  \n",
    "# )\n",
    "\n",
    "for tool in agent.tools:\n",
    "    if isinstance(tool, FunctionTool):\n",
    "        print(tool.name)\n",
    "        print(tool.description)\n",
    "        print(json.dumps(tool.params_json_schema, indent=2))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
