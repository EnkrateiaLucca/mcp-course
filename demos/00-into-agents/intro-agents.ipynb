{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "# Introduction to AI Agents\n",
    "\n",
    "This notebook demonstrates how AI agents work, from basic function calling to a complete agentic loop.\n",
    "\n",
    "## What is an Agent?\n",
    "\n",
    "An AI agent is a system where an LLM can:\n",
    "1. Decide which tools/functions to call\n",
    "2. Execute those tools\n",
    "3. Use the results to take further actions\n",
    "4. Continue until the task is complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "import os\n",
    "import json\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "## Step 1: Basic Python Functions\n",
    "\n",
    "First, let's create some simple Python functions that our agent will be able to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sunny, 72°F\n",
      "105\n"
     ]
    }
   ],
   "source": [
    "def get_weather(location: str) -> str:\n",
    "    \"\"\"Get the current weather for a location.\"\"\"\n",
    "    # This is a mock function - in reality, you'd call a weather API\n",
    "    weather_data = {\n",
    "        \"san francisco\": \"sunny, 72°F\",\n",
    "        \"new york\": \"cloudy, 65°F\",\n",
    "        \"london\": \"rainy, 58°F\",\n",
    "        \"tokyo\": \"clear, 68°F\"\n",
    "    }\n",
    "    location_lower = location.lower()\n",
    "    return weather_data.get(location_lower, f\"Weather data not available for {location}\")\n",
    "\n",
    "def calculate(operation: str, a: float, b: float) -> float:\n",
    "    \"\"\"Perform a mathematical calculation.\"\"\"\n",
    "    operations = {\n",
    "        \"add\": a + b,\n",
    "        \"subtract\": a - b,\n",
    "        \"multiply\": a * b,\n",
    "        \"divide\": a / b if b != 0 else \"Error: Division by zero\"\n",
    "    }\n",
    "    return operations.get(operation, \"Error: Unknown operation\")\n",
    "\n",
    "def create_directory(directory_name: str) -> str:\n",
    "    \"\"\"Create a new directory.\"\"\"\n",
    "    try:\n",
    "        os.makedirs(directory_name, exist_ok=True)\n",
    "        return f\"Successfully created directory: {directory_name}\"\n",
    "    except Exception as e:\n",
    "        return f\"Error creating directory: {str(e)}\"\n",
    "\n",
    "# Test our functions\n",
    "print(get_weather(\"San Francisco\"))\n",
    "print(calculate(\"multiply\", 15, 7))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "## Step 2: Define Tools for the LLM\n",
    "\n",
    "Now we need to describe our functions in a format the LLM can understand. This is done using JSON schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defined 3 tools for the LLM\n"
     ]
    }
   ],
   "source": [
    "tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"get_weather\",\n",
    "            \"description\": \"Get the current weather for a location\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"location\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"The city name, e.g. San Francisco\"\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"location\"]\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"calculate\",\n",
    "            \"description\": \"Perform a mathematical calculation\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"operation\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"enum\": [\"add\", \"subtract\", \"multiply\", \"divide\"],\n",
    "                        \"description\": \"The mathematical operation to perform\"\n",
    "                    },\n",
    "                    \"a\": {\n",
    "                        \"type\": \"number\",\n",
    "                        \"description\": \"The first number\"\n",
    "                    },\n",
    "                    \"b\": {\n",
    "                        \"type\": \"number\",\n",
    "                        \"description\": \"The second number\"\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"operation\", \"a\", \"b\"]\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"create_directory\",\n",
    "            \"description\": \"Create a new directory on the file system\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"directory_name\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"The name of the directory to create\"\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"directory_name\"]\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "# Map function names to actual Python functions\n",
    "available_functions = {\n",
    "    \"get_weather\": get_weather,\n",
    "    \"calculate\": calculate,\n",
    "    \"create_directory\": create_directory\n",
    "}\n",
    "\n",
    "print(f\"Defined {len(tools)} tools for the LLM\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "## Step 3: Single Function Call Example\n",
    "\n",
    "Let's see how the LLM decides to call a function and how we execute it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM Response:\n",
      "Content: None\n",
      "Tool calls: [ChatCompletionMessageFunctionToolCall(id='call_RcQULoqAhIGEK56vBJ7sXbj2', function=Function(arguments='{\"location\":\"Tokyo\"}', name='get_weather'), type='function')]\n"
     ]
    }
   ],
   "source": [
    "# Create a simple query\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"What's the weather in Tokyo?\"}\n",
    "]\n",
    "\n",
    "# Send to OpenAI with tools available\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=messages,\n",
    "    tools=tools,\n",
    "    tool_choice=\"auto\"  # Let the model decide when to use tools\n",
    ")\n",
    "\n",
    "response_message = response.choices[0].message\n",
    "print(\"LLM Response:\")\n",
    "print(f\"Content: {response_message.content}\")\n",
    "print(f\"Tool calls: {response_message.tool_calls}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "The LLM decided to call a function! Let's execute it and send the result back."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the model called a function\n",
    "if response_message.tool_calls:\n",
    "    # Add the assistant's response to messages\n",
    "    messages.append(response_message)\n",
    "    \n",
    "    # Execute each tool call\n",
    "    for tool_call in response_message.tool_calls:\n",
    "        function_name = tool_call.function.name\n",
    "        function_args = json.loads(tool_call.function.arguments)\n",
    "        \n",
    "        print(f\"\\nCalling function: {function_name}\")\n",
    "        print(f\"With arguments: {function_args}\")\n",
    "        \n",
    "        # Get the actual function and call it\n",
    "        function_to_call = available_functions[function_name]\n",
    "        function_response = function_to_call(**function_args)\n",
    "        \n",
    "        print(f\"Function returned: {function_response}\")\n",
    "        \n",
    "        # Add the function response to messages\n",
    "        messages.append({\n",
    "            \"tool_call_id\": tool_call.id,\n",
    "            \"role\": \"tool\",\n",
    "            \"name\": function_name,\n",
    "            \"content\": str(function_response)\n",
    "        })\n",
    "    \n",
    "    # Get the final response from the model\n",
    "    final_response = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=messages\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nFinal Response: {final_response.choices[0].message.content}\")\n",
    "else:\n",
    "    print(\"No function was called\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "## Step 4: Multi-Step Agent Loop\n",
    "\n",
    "Now let's create a complete agentic loop that can handle multiple tool calls until the task is complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: What's the weather in London?\n",
      "\n",
      "--- Iteration 1 ---\n",
      "Tool call: get_weather({'location': 'London'})\n",
      "Tool response: rainy, 58°F\n",
      "\n",
      "--- Iteration 2 ---\n",
      "Agent (final): The weather in London is rainy with a temperature of 58°F.\n",
      "\n",
      "The weather in London is rainy with a temperature of 58°F.\n"
     ]
    }
   ],
   "source": [
    "def run_agent(user_query: str, max_iterations: int = 5) -> str:\n",
    "    \"\"\"\n",
    "    Run an agentic loop that can make multiple tool calls.\n",
    "    \n",
    "    Args:\n",
    "        user_query: The user's request\n",
    "        max_iterations: Maximum number of back-and-forth iterations\n",
    "    \n",
    "    Returns:\n",
    "        The final response from the agent\n",
    "    \"\"\"\n",
    "    messages = [{\"role\": \"user\", \"content\": user_query}]\n",
    "    \n",
    "    print(f\"User: {user_query}\\n\")\n",
    "    \n",
    "    for iteration in range(max_iterations):\n",
    "        print(f\"--- Iteration {iteration + 1} ---\")\n",
    "        \n",
    "        # Get response from the model\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=messages,\n",
    "            tools=tools,\n",
    "            tool_choice=\"auto\"\n",
    "        )\n",
    "        \n",
    "        response_message = response.choices[0].message\n",
    "        \n",
    "        # If no tool calls, we're done\n",
    "        if not response_message.tool_calls:\n",
    "            print(f\"Agent (final): {response_message.content}\\n\")\n",
    "            return response_message.content\n",
    "        \n",
    "        # Add assistant's response to messages\n",
    "        messages.append(response_message)\n",
    "        \n",
    "        # Execute all tool calls\n",
    "        for tool_call in response_message.tool_calls:\n",
    "            function_name = tool_call.function.name\n",
    "            function_args = json.loads(tool_call.function.arguments)\n",
    "            \n",
    "            print(f\"Tool call: {function_name}({function_args})\")\n",
    "            \n",
    "            # Execute the function\n",
    "            function_to_call = available_functions[function_name]\n",
    "            function_response = function_to_call(**function_args)\n",
    "            \n",
    "            print(f\"Tool response: {function_response}\")\n",
    "            \n",
    "            # Add function response to messages\n",
    "            messages.append({\n",
    "                \"tool_call_id\": tool_call.id,\n",
    "                \"role\": \"tool\",\n",
    "                \"name\": function_name,\n",
    "                \"content\": str(function_response)\n",
    "            })\n",
    "        \n",
    "        print()\n",
    "    \n",
    "    return \"Max iterations reached\"\n",
    "\n",
    "# Test with a simple query\n",
    "result = run_agent(\"What's the weather in London?\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "## Step 5: Complex Multi-Tool Query\n",
    "\n",
    "Now let's test with a query that requires multiple tool calls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: What's the weather in San Francisco and New York?\n",
      "    Then multiply the numbers in their temperatures together.\n",
      "\n",
      "--- Iteration 1 ---\n",
      "Tool call: get_weather({'location': 'San Francisco'})\n",
      "Tool response: sunny, 72°F\n",
      "Tool call: get_weather({'location': 'New York'})\n",
      "Tool response: cloudy, 65°F\n",
      "\n",
      "--- Iteration 2 ---\n",
      "Tool call: calculate({'operation': 'multiply', 'a': 72, 'b': 65})\n",
      "Tool response: 4680\n",
      "\n",
      "--- Iteration 3 ---\n",
      "Agent (final): The weather in San Francisco is sunny with a temperature of 72°F, while in New York, it is cloudy with a temperature of 65°F. When you multiply the temperatures together, the result is 4680.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The weather in San Francisco is sunny with a temperature of 72°F, while in New York, it is cloudy with a temperature of 65°F. When you multiply the temperatures together, the result is 4680.'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = run_agent(\n",
    "    \"\"\"What's the weather in San Francisco and New York?\n",
    "    Then multiply the numbers in their temperatures together.\"\"\"\n",
    ")\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "## Step 6: Action-Based Query\n",
    "\n",
    "Let's test with a query that performs an action (creates a directory)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: Create a folder called 'agent-test-directory'\n",
      "\n",
      "--- Iteration 1 ---\n",
      "Tool call: create_directory({'directory_name': 'agent-test-directory'})\n",
      "Tool response: Successfully created directory: agent-test-directory\n",
      "\n",
      "--- Iteration 2 ---\n",
      "Agent (final): The folder 'agent-test-directory' has been successfully created.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"The folder 'agent-test-directory' has been successfully created.\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = run_agent(\"Create a folder called 'agent-test-directory'\")\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "## Key Takeaways\n",
    "\n",
    "1. **Function Calling**: The LLM can decide which functions to call based on the user's query\n",
    "2. **Tool Execution**: We execute the requested functions and return results to the LLM\n",
    "3. **Agentic Loop**: By repeatedly calling the LLM with tool results, we create an agent that can:\n",
    "   - Break down complex tasks\n",
    "   - Make multiple tool calls\n",
    "   - Use results from one tool call to inform the next\n",
    "   - Continue until the task is complete\n",
    "\n",
    "This is the foundation of how AI agents work - they bridge the gap between language understanding and taking real actions!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
